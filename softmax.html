<!DOCTYPE html>
<html lang="en" data-theme="light">

<head>
    <title>Mahitha Chodavarapu | Learnings</title>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <meta name="application-name" content="Mahitha Chodavarapu | Home" />
    <meta name="apple-mobile-web-app-title" content="Mahitha Chodavarapu | Home" />
    
    <!--For Dark/Light mode Toggle-->
    <script src="https://code.iconify.design/1/1.0.4/iconify.min.js"></script>
    <!--Import Google Icon Font-->
    <link href="assets/img/favicon.png" rel="icon">
    <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

    <!-- Google Fonts -->
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i" rel="stylesheet">

    <!-- Vendor CSS Files -->
    <link href="assets/vendor/aos/aos.css" rel="stylesheet">
    <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
    <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
    <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
    <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
    <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

    <!-- Template Main CSS File -->
    <link href="assets/css/style1.css" rel="stylesheet">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" />
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@200;300&display=swap" rel="stylesheet">
    <script src='https://kit.fontawesome.com/a076d05399.js'></script>
    <link rel="stylesheet" href="assets/css/preloader.css">
    <link rel="stylesheet" href="assets/css/home.css"> 
    <link rel="stylesheet" href="assets/css/style.css"> 
    <!-- Favicon -->
    <link id='favicon' rel="shortcut icon" href="assets/images/favicon.png" type="image/x-png"> 
    <!-- Font awesome icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css" integrity="sha512-+4zCK9k+qNFUR5X+cKL9EIR+ZOhtIloNl9GIKS57V1MyNsYpYcUrUeQc9vNfzsWfV28IaLL3i96P9sdNyeRssA==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <script defer src="assets\js\dynamicTitle.js"></script>
</head>

<body>
<!-- loader -->
<br>
<br>
      
<section id="about" class="about">
      <div class="container" data-aos="fade-up">

        <div class="section-title">
          <h2>Softmax</h2>
          <h2>Introduction</h2>
<p>The activation function is an integral part of a neural network. Without an activation function, a neural network is a simple linear regression model. This means the activation function gives non-linearity to the neural network.</p>

<h2>Example</h2>
<p>Suppose, we have the following dataset and for every observation, we have five features from FeatureX1 to FeatureX5 and the target variable has three classes.</p>
<p><img loading="lazy" class="aligncenter wp-image-77504 size-full" src="https://cdn.analyticsvidhya.com/wp-content/uploads/2021/04/Screenshot-from-2021-04-01-17-23-11.png" alt="Softmax data" width="485" height="240" srcset="https://cdn.analyticsvidhya.com/wp-content/uploads/2021/04/Screenshot-from-2021-04-01-17-23-11.png 485w, https://cdn.analyticsvidhya.com/wp-content/uploads/2021/04/Screenshot-from-2021-04-01-17-23-11-300x148.png 300w" sizes="(max-width: 485px) 100vw, 485px" /></p>
<p>&nbsp;</p>
<p>Now let&#8217;s create a simple neural network for this problem. Here, we have an Input layer with five neurons as we have five features in the dataset. Next, we have one hidden layer which has four neurons. Each of these neurons uses inputs, weights, and biases here to calculate a value which is represented as Zij here.</p>
<p><img loading="lazy" class="aligncenter wp-image-77503 size-full" src="https://cdn.analyticsvidhya.com/wp-content/uploads/2021/04/Screenshot-from-2021-04-01-17-24-06.png" alt="neural network softmax" width="531" height="297" srcset="https://cdn.analyticsvidhya.com/wp-content/uploads/2021/04/Screenshot-from-2021-04-01-17-24-06.png 531w, https://cdn.analyticsvidhya.com/wp-content/uploads/2021/04/Screenshot-from-2021-04-01-17-24-06-300x168.png 300w, https://cdn.analyticsvidhya.com/wp-content/uploads/2021/04/Screenshot-from-2021-04-01-17-24-06-257x144.png 257w" sizes="(max-width: 531px) 100vw, 531px" /></p>
<p>For example, the first neuron of the first layer is represented as Z11 Similarly the second neuron of the first layer is represented as Z12, and so on.</p>
<p>Over these values, we apply the activation function. Let&#8217;s say a tanh activation function and send the values or result to the output layer.</p>
<p>The number of neurons in the output layer depends on the number of classes in the dataset. Since we have three classes in the dataset we will have three neurons in the output layer. Each of these neurons will give the probability of individual classes. This means the first neuron will give you the probability that the data point belongs to class 1. Similarly, the second neuron will give you the probability that the data point belongs to class 2 and so on.</p>
<p>&nbsp;</p>
<h2>Why Not Sigmoid?</h2>
<p>Suppose we calculate the Z value using weights and biases of this layer and apply the sigmoid activation function over these values. We know that the sigmoid activation function gives the value between 0 and 1. suppose these are the values we get as output.</p>
<p><img loading="lazy" class="aligncenter wp-image-77499 size-full" src="https://cdn.analyticsvidhya.com/wp-content/uploads/2021/04/Screenshot-from-2021-04-01-17-24-34.png" alt="sigmoid softmax" width="629" height="364" srcset="https://cdn.analyticsvidhya.com/wp-content/uploads/2021/04/Screenshot-from-2021-04-01-17-24-34.png 629w, https://cdn.analyticsvidhya.com/wp-content/uploads/2021/04/Screenshot-from-2021-04-01-17-24-34-300x174.png 300w" sizes="(max-width: 629px) 100vw, 629px" /></p>
<p>There are two problems in this case-</p>
<p>First, if we apply a thresh-hold of say 0.5, this network says the input data point belongs to two classes. Secondly, these probability values are independent of each other. That means the probability that the data point belongs to class 1 does not take into account the probability of the other two classes.</p>
<p>This is the reason the sigmoid activation function is not preferred in multi-class classification problems.</p>
<p>&nbsp;</p>
<h2>Softmax Activation</h2>
<p>Instead of using sigmoid, we will use the Softmax activation function in the output layer in the above example. The Softmax activation function calculates the relative probabilities. That means it uses the value of Z21, Z22, Z23 to determine the final probability value.</p>
<p>Let&#8217;s see how the softmax activation function actually works. Similar to the sigmoid activation function the SoftMax function returns the probability of each class. Here is the equation for the SoftMax activation function.</p>
<p><img loading="lazy" class="aligncenter wp-image-77501 size-full" src="https://cdn.analyticsvidhya.com/wp-content/uploads/2021/04/Screenshot-from-2021-04-01-17-25-22.png" alt="SoftMax Activation formula" width="317" height="100" srcset="https://cdn.analyticsvidhya.com/wp-content/uploads/2021/04/Screenshot-from-2021-04-01-17-25-22.png 317w, https://cdn.analyticsvidhya.com/wp-content/uploads/2021/04/Screenshot-from-2021-04-01-17-25-22-300x95.png 300w" sizes="(max-width: 317px) 100vw, 317px" /></p>
<p>Here, the Z represents the values from the neurons of the output layer. The exponential acts as the non-linear function. Later these values are divided by the sum of exponential values in order to normalize and then convert them into probabilities.</p>
<p>Note that, when the number of classes is two, it becomes the same as the sigmoid activation function. In other words, sigmoid is simply a variant of the Softmax function. If you want to learn more about this concept.</p>
<p>Let&#8217;s understand with a simple example how the softmax works, We have the following neural network.</p>
<p><img loading="lazy" class="aligncenter wp-image-77498 size-full" src="https://cdn.analyticsvidhya.com/wp-content/uploads/2021/04/Screenshot-from-2021-04-01-17-25-02.png" alt="SoftMax Activation Multiclass problem" width="610" height="364" srcset="https://cdn.analyticsvidhya.com/wp-content/uploads/2021/04/Screenshot-from-2021-04-01-17-25-02.png 610w, https://cdn.analyticsvidhya.com/wp-content/uploads/2021/04/Screenshot-from-2021-04-01-17-25-02-300x179.png 300w" sizes="(max-width: 610px) 100vw, 610px" /></p>
<p>Suppose the value of Z21, Z22, Z23 comes out to be 2.33, -1.46, and 0.56 respectively. Now the SoftMax activation function is applied to each of these neurons and the following values are generated.</p>
<p><img loading="lazy" class="aligncenter wp-image-77497 size-full" src="https://cdn.analyticsvidhya.com/wp-content/uploads/2021/04/Screenshot-from-2021-04-01-17-26-04.png" alt="hidden layer" width="631" height="292" srcset="https://cdn.analyticsvidhya.com/wp-content/uploads/2021/04/Screenshot-from-2021-04-01-17-26-04.png 631w, https://cdn.analyticsvidhya.com/wp-content/uploads/2021/04/Screenshot-from-2021-04-01-17-26-04-300x139.png 300w" sizes="(max-width: 631px) 100vw, 631px" /></p>
<p>These are the probability values that a data point belonging to the respective classes. Note that, the sum of the probabilities, in this case, is equal to 1.</p>
<p><img loading="lazy" class="aligncenter wp-image-77500 size-full" src="https://cdn.analyticsvidhya.com/wp-content/uploads/2021/04/Screenshot-from-2021-04-01-17-26-10.png" alt="sum of the probabilities in this case is equal to 1." width="529" height="264" srcset="https://cdn.analyticsvidhya.com/wp-content/uploads/2021/04/Screenshot-from-2021-04-01-17-26-10.png 529w, https://cdn.analyticsvidhya.com/wp-content/uploads/2021/04/Screenshot-from-2021-04-01-17-26-10-300x150.png 300w" sizes="(max-width: 529px) 100vw, 529px" /></p>
<p>In this case it clear that the input belongs to class 1. So if the probability of any of ï¿¼these classes is changed, the probability value of the first class would also change.</p>
         
        </div>
 </div>
    </section><!-- End About Section -->


    


    <!-- Dynamic footer section -->
    <script src="https://code.jquery.com/jquery-3.5.1.min.js"
        integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>

    <!-- Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-167979537-2"></script>
    <!-- Fetching our Google Tag Manager -->

    <!--JavaScript at end of body for optimized loading-->
    <script src="assets/js/app.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>
    <script src='https://cdnjs.cloudflare.com/ajax/libs/particles.js/2.0.0/particles.min.js'></script>
    <script src="assets/js/particle.js"></script>

</body>

</html>